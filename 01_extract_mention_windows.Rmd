---
title: "Extract Mention Windows"
output: html_document
---


The purpose of this script is to read in all PDFs from 2010-2015 and extract the senteces matching CIG software, with a window of one sentence before and after the software mention.

Packages.
```{r}
library(pdftools)
library(tokenizers)
library(stringr)
library(tidyr)
library(dplyr)
library(readr)
```


Vector of package names.
```{r}
cig <- c("ASPECT", 
"AxiSEM",
"Burnman",
"Calypso",
"Citcom",
"ConMan",
"Ellipsis3d",
"FLEXWIN",
" Gale ",    # avoid "Galerkin"
" MAG ",     # avoid picking up "magnetic", "magnitude", etc..
"Mineos",
"PyLith",
"Rayleigh",
"RELAX",
"SEISMIC_CPML",
"SELEN",
"SNAC",
"SPECFEM",
"SW4",
"Virtual California")
```


```{r}
fp <- "C:/Users/rpauloo/Desktop/2019 CItation/Papers/" # PC
# fp <- "/Users/richpauloo/Desktop/2019 CItation/Papers/" # Mac

# paper names
p <- list.files(paste0(fp, "all_papers")) 
```

For one PDF, get vector of paper file names, read in the first one, tokenize sentences, and extract the mention window.
```{r}
# # pdf_info(paste0(fp, "all_papers/", p[1])) # metadata: can grab all DOI
# 
# # read all pdfs
# raw <- paste(pdf_text(paste0(fp, "all_papers/", p[1])), collapse = " ")
#   
# # tokensize sentence with tokenizers package
# rs <- tokenize_sentences(raw[1])                      # tokenize sentences
# rs <- lapply(rs, function(x){paste(x, collapse = " ")}) # collapse each list element
# 
# # do for one
# x = rs[[1]]
# 
# # grabs mention window if a software (y) is mentioned
# match_words <- function(y){
#   hold <- NA
#   i    <- str_which(x, y)
#   if(!identical(i, integer(0))){
#     hold <- paste(x[i-2], x[i-1], x[i], x[i+1], x[i+2])
#   }
#   # hold <- data.frame(match = y, matches = hold)
#   return(hold)
# }
# 
# # applies vector of software names to `match_words` to get list of all windows
# matches <- lapply(cig, match_words)
# 
# # name the list by software name, filter out NA, and organize into a dataframe
# names(matches) <- cig
# matches <- matches[!is.na(matches)] 
# data.frame(matches) %>% 
#   gather(software_name, value) %>% 
#   distinct()
```

Generalize process to all PDFs.
```{r}
# function to read PDFs
read_pdfs <- function(p){
  paste(pdf_text(paste0(fp, "all_papers/", p)), collapse = " ")
}

# read all pdfs into a list: takes a while
# raw <- lapply(p, read_pdfs)
# readr::write_rds(raw, "raw.rds") # save the data
raw <- read_rds("raw.rds")

# tokenize sentences
rs <- tokenize_sentences(raw)

# find mention windows for all words in all PDFs

# function to match words and return mention windows within one PDF
match_words <- function(y){
  
  # intialize return variable
  hold <- NA
  
  # get index of all word matches
  i    <- str_which(x, y)  
  
  # if there's a match
  if(!identical(i, integer(0))){ 
    # case 1: match at first sentence
    if(1 %in% i){
      hold <- paste(x[i], x[i+1], x[i+2])
    }
    # case 2: match at second sentence
    else if(2 %in% i){
      hold <- paste(x[i-1], x[i], x[i+1], x[i+2])
    }
    # case 3: match at last sentence
    else if(length(x) %in% i){
      hold <- paste(x[i-2], x[i-1], x[i])
    }
    # case 4: match at second to last sentence
    else if((length(x) - 1) %in% i){
      hold <- paste(x[i-2], x[i-1], x[i], x[i+1])
    }
    # case 5: match NOT at 1st, 2nd, 2nd to last, or last sentence
    else{
      hold <- paste(x[i-2], x[i-1], x[i], x[i+1], x[i+2])
    }
  }
  return(hold) # original working
  # return(list(hold, i))
  # return(data.frame(sen = hold, i = i)) # adding sentence index to hold vector
}

# initalize list that will store all clean data frames
# df <- vector("list", length = length(p)) # for ALL papers
df <- vector("list", length = length(raw)) # testing with one paper

# loop over all PDFs, and grab mention windows
# for(i in 1:length(p)){
for(i in 1:length(raw)){
  x = rs[[i]]                          # select PDF text
  matches <- lapply(cig, match_words)  # find matches
  names(matches) <- cig                # name list element by software
  matches <- matches[!is.na(matches)]  # remove non-matches (NA)
  
  # new code - remove NA from non-software matches, and 
  # integer(0) from non
  # mn <- lapply(matches, `[[`, 1)
  # mn <- mn[!is.na(mn)]  
  # mi <- lapply(matches, `[[`, 2)
  # mi <- mi[!is.na(mn)]
  
  
  nam <- names(matches)                # retreive names of remaining software
  # nam <- names(mn)                # retreive names of remaining software
  
  temp <- lapply(matches, function(z){ # gather each list into a dataframe
    gather(data.frame(z), software_name, value)})
  
  # new code
  # temp <- lapply(mn, function(z){ # gather each list into a dataframe
  #   gather(data.frame(z), software_name, value)})
  # 
  # temp2 <- lapply(mi, function(z){ # gather each list into a dataframe
  #   gather(data.frame(z), software_name, index)})
  
  if(length(temp) > 0){
    # get the software name for each df
    for(j in 1:length(temp)){         
      temp[[j]]$software_name <- nam[j]
    }
    temp <- do.call(rbind.data.frame, temp) # make into one df
    temp$paper <- p[i]                      # add file name of paper
    rownames(temp) <- NULL                  # remove rownames
    df[[i]] <- temp                         # store in main list
  }
  
  # new code
  # if(length(temp) > 0){
  #   for(j in 1:length(mn)){         # fill in the software name for each df
  #     temp[[j]]$software_name <- nam[j]
  #   }
  #   temp <- do.call(rbind.data.frame, temp) # make into one df
  #   temp2 <- do.call(rbind.data.frame, temp2) # make into one df
  #   temp$paper <- p[i]                      # add file name of paper
  #   temp2$paper <- p[i]                      # add file name of paper
  #   rownames(temp) <- NULL                  # remove rownames
  #   rownames(temp2) <- NULL                  # remove rownames
  #   temp3 <- left_join(temp, temp2, by = "paper")
  #   df[[i]] <- temp3                        # store in main list
  # }
  
  if(length(temp) == 0){
    df[[i]]$software_name <- NA
    df[[i]]$value         <- NA
    df[[i]]$paper         <- p[i]
  }
}

# combine into one final data frame
final <- do.call(rbind.data.frame, df)

# number of papers that don't mention one of the softwares.
nrow(filter(final, is.na(software_name)))

# names of papers missing a software package
pull(filter(final, is.na(software_name)), paper)
```



***

Now grab sentence token *index* at which software mention occurs, and the sentence token *length* per paper. The ratio of: $\frac{token \space index}{ token \space length}$ is an indication of where in the paper the mention occurs. In the future, can omit References (last mention of "references" and beyond). But as a first pass, this is okay.  

```{r}
myfun <- function(y){
  
  # intialize return variable
  hold <- NA
  
  # get index of all word matches
  i <- str_which(x, y)  

  return(hold) # original working
  return(data.frame(sen = hold, i = i)) # adding sentence index to hold vector
}

df <- list()

for(i in 1:1){
  x = rs[[i]]                          # select PDF text
  matches <- lapply(cig, myfun)        # find matches
  names(matches) <- cig                # name list element by software
  matches <- matches[!is.na(matches)]  # remove non-matches (NA)
  
  nam <- names(matches)                # retreive names of remaining software
  temp <- lapply(matches, function(z){ # gather each list into a dataframe
    gather(data.frame(z), software_name, value)}) 
  
  if(length(temp) > 0){
    for(j in 1:length(matches)){         # fill in the software name for each df
      temp[[j]]$software_name <- nam[j]
    }
    temp <- do.call(rbind.data.frame, temp) # make into one df
    temp$paper <- p[i]                      # add file name of paper
    rownames(temp) <- NULL                  # remove rownames
    df[[i]] <- temp                         # store in main list
  }
  
  if(length(temp) == 0){
    df[[i]] <- NA
  }
}



```



Combine with Duncan's ReadPDF
```{r}
# first paper's names(ReadPDF::getSectionText(p[1])), where p[1] is XML
zn <- c("", "Introduction", "", "Numerical Model of Fault Slip", "", 
"Finite-Element Mesh Processing", "", "Solver Customization", 
"", "Performance Benchmark", "", "Code Verification Benchmarks", 
"", "Conclusions", "", "Notation", "References", "<other>", "Table1", 
"Table2", "Table3", "Table4", "Table5", "Table6", "Table7", "Table8"
)

# remove artifacts from ReadPDF
zn <- zn[! zn %in% c("", "<other>") ] 
z <- zn[-str_which(zn, "Table")]      # vector of terms to search


# look for indices of z in pdf_text of p[1]
raw[[1]] # p[1]
rs[[1]]  # p[1]

```



Repeat with lowercase.
```{r}
rsl  <- lapply(rs, tolower)
cigl <- tolower(cig)


# intalize list that will store all clean data frames
df <- vector("list", length = length(p)) 

# loop over all PDFs, and grab mention windows
library(tidyr)
for(i in 1:length(p)){
  x = rsl[[i]]                          # select PDF text
  matches <- lapply(cigl, match_words)  # find matches
  names(matches) <- cigl                # name list element by software
  matches <- matches[!is.na(matches)]  # remove non-matches (NA)
  
  nam <- names(matches)                # retreive names of remaining software
  temp <- lapply(matches, function(z){ # gather each list into a dataframe
    gather(data.frame(z), software_name, value)}) 
  
  if(length(temp) > 0){
    for(j in 1:length(matches)){         # fill in the software name for each df
      temp[[j]]$software_name <- nam[j]
    }
    temp <- do.call(rbind.data.frame, temp) # make into one df
    temp$paper <- p[i]                      # add file name of paper
    rownames(temp) <- NULL                  # remove rownames
    df[[i]] <- temp                         # store in main list
  }
  
  if(length(temp) == 0){
    df[[i]] <- NA
  }
}

# combine into one final data frame
final <- do.call(rbind.data.frame, df)
```


```{r}
final %>% 
  group_by(software_name) %>% 
  summarise(n_papers = n_distinct(paper)) %>% 
  filter(!is.na(software_name)) %>% 
  arrange(desc(n_papers))

final %>% 
  group_by(software_name) %>% 
  summarise(n_papers = n_distinct(paper)) %>% 
  filter(!is.na(software_name)) %>% 
  arrange(desc(n_papers)) %>% 
  filter(software_name != "rayleigh") %>% 
  pull(n_papers) %>% 
  sum()
```


